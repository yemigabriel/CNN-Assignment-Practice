{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(74370) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.66.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow)\n",
      "  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow)\n",
      "  Using cached optree-0.12.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl (236.3 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.1-cp312-cp312-macosx_10_9_universal2.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl (405 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.9/284.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 keras-3.5.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "#install tensorflow to get access to the keras dataset\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # Should display the installed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(74650) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "#install scikit-learn for tasks such as partitioning dataset into training and validation sets\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values (0-255 -> 0-1)\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition training set into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split 10% of the training data for validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model... Here, you define the loss function, optimizer, and metrics:\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 83ms/step - accuracy: 0.3708 - loss: 1.7283 - val_accuracy: 0.5856 - val_loss: 1.1902\n",
      "Epoch 2/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 68ms/step - accuracy: 0.5836 - loss: 1.1726 - val_accuracy: 0.6402 - val_loss: 1.0335\n",
      "Epoch 3/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 73ms/step - accuracy: 0.6416 - loss: 1.0243 - val_accuracy: 0.6510 - val_loss: 1.0037\n",
      "Epoch 4/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 73ms/step - accuracy: 0.6819 - loss: 0.9070 - val_accuracy: 0.6858 - val_loss: 0.8990\n",
      "Epoch 5/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 86ms/step - accuracy: 0.7145 - loss: 0.8155 - val_accuracy: 0.7026 - val_loss: 0.8513\n",
      "Epoch 6/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 57ms/step - accuracy: 0.7423 - loss: 0.7389 - val_accuracy: 0.6966 - val_loss: 0.8756\n",
      "Epoch 7/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 57ms/step - accuracy: 0.7652 - loss: 0.6704 - val_accuracy: 0.7206 - val_loss: 0.8219\n",
      "Epoch 8/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 49ms/step - accuracy: 0.7835 - loss: 0.6098 - val_accuracy: 0.7204 - val_loss: 0.8071\n",
      "Epoch 9/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 52ms/step - accuracy: 0.8062 - loss: 0.5482 - val_accuracy: 0.7236 - val_loss: 0.7963\n",
      "Epoch 10/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 52ms/step - accuracy: 0.8278 - loss: 0.5007 - val_accuracy: 0.7408 - val_loss: 0.7896\n",
      "Epoch 11/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 47ms/step - accuracy: 0.8441 - loss: 0.4447 - val_accuracy: 0.7334 - val_loss: 0.8194\n",
      "Epoch 12/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 51ms/step - accuracy: 0.8565 - loss: 0.4074 - val_accuracy: 0.7378 - val_loss: 0.8418\n",
      "Epoch 13/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 48ms/step - accuracy: 0.8724 - loss: 0.3575 - val_accuracy: 0.7384 - val_loss: 0.8681\n",
      "Epoch 14/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.8809 - loss: 0.3344 - val_accuracy: 0.7348 - val_loss: 0.8931\n",
      "Epoch 15/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 57ms/step - accuracy: 0.8959 - loss: 0.2991 - val_accuracy: 0.7348 - val_loss: 0.9220\n",
      "Epoch 16/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 60ms/step - accuracy: 0.9017 - loss: 0.2768 - val_accuracy: 0.7336 - val_loss: 0.9131\n",
      "Epoch 17/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 63ms/step - accuracy: 0.9091 - loss: 0.2573 - val_accuracy: 0.7292 - val_loss: 0.9458\n",
      "Epoch 18/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.9135 - loss: 0.2421 - val_accuracy: 0.7340 - val_loss: 0.9886\n",
      "Epoch 19/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 50ms/step - accuracy: 0.9177 - loss: 0.2307 - val_accuracy: 0.7352 - val_loss: 1.0707\n",
      "Epoch 20/20\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 58ms/step - accuracy: 0.9251 - loss: 0.2130 - val_accuracy: 0.7364 - val_loss: 1.0274\n"
     ]
    }
   ],
   "source": [
    "#5 Train the model\n",
    "# Define the number of epochs and include validation data for tuning:\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,  # Adjust the number of epochs based on early stopping or training curves\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    batch_size=64)  # Adjust batch size based on memory capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "# Once the model has finished learning, we check how well it performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7352 - loss: 1.0581\n",
      "Test accuracy: 0.7318000197410583\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(76788) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.3.0)\n"
     ]
    }
   ],
   "source": [
    "#test model .... install pillow to handle images\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess your image\n",
    "def load_and_preprocess_image(image_path):\n",
    "    # Open the image file\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Ensure the image has 3 channels (RGB), even if it's RGBA (with transparency)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    # Resize the image to 32x32 pixels (as CIFAR-10 images are 32x32)\n",
    "    img = img.resize((32, 32))\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Plot the image for reference\n",
    "    plt.imshow(img_array)\n",
    "    plt.show()\n",
    "    \n",
    "    # Scale pixel values to the [0, 1] range (just like we did for training images)\n",
    "    img_array = img_array.astype('float32') / 255.0\n",
    "    \n",
    "    # Expand dimensions to match the model's expected input shape (1, 32, 32, 3)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "# Path to your image\n",
    "image_path = 'image.png'\n",
    "\n",
    "# Preprocess the image\n",
    "test_image = load_and_preprocess_image(image_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Model to Predict the Object Category\n",
    "Now that the image is loaded and preprocessed, you can pass it to your trained model to get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "The model predicts this is a: dog\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to predict the class\n",
    "predictions = model.predict(test_image)\n",
    "\n",
    "# CIFAR-10 class names (since predictions will be numbers 0-9)\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Get the predicted class (the highest probability)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Output the predicted class name\n",
    "print(f\"The model predicts this is a: {class_names[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
